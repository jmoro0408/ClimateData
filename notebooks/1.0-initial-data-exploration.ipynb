{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc459c8-d337-4abd-920d-4d5b97674ee2",
   "metadata": {},
   "source": [
    "# Imports and spark setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dbe330-50b0-4ee3-af4a-e6a9587a6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "from src.utils import DisplayablePath\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821b63b0-ba00-4f48-8cc2-bb4e99009a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missings(spark_df,sort=True):\n",
    "    \"\"\"\n",
    "    Counts number of nulls and nans in each column\n",
    "    \"\"\"\n",
    "    df = spark_df.select([F.count(F.when(F.isnan(c) | F.isnull(c), c)).alias(c) for (c,c_type) in spark_df.dtypes if c_type not in ('timestamp', 'string', 'date')]).toPandas()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"There are no any missing values!\")\n",
    "        return None\n",
    "\n",
    "    if sort:\n",
    "        return df.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8025ca-4722-4e94-a1b4-36d5c76660a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_read_csv(filepath):\n",
    "    df = spark.read.load(filepath,format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62199f4f-9977-46e4-8bb8-af175c646e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_summary(df):\n",
    "    print(\"----------------------\")\n",
    "    #print(df.head(2))\n",
    "    print(df.printSchema())\n",
    "    print(f\"There are {df.count()} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4618a0ec-215d-4d78-ac5e-54d35771f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_spark():\n",
    "    return sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797707ec-a18d-4ff8-a6f7-64fa0cbe9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPNAME=\"ClimateChange\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2862cc1f-11ad-4ca9-a637-cf7fc7dbea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/13 11:38:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Users/jamesmoro/server/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(APPNAME).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc1bad5-525d-4c6c-a63a-c77d60c33eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e607f-4d09-4b56-bce5-742646380242",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86e60e6-1f43-4203-a94d-1263c1e71b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw/\n",
      "├── .DS_Store\n",
      "├── .gitkeep\n",
      "├── climate_change_download_0.xls\n",
      "├── GlobalTemperatures/\n",
      "│   ├── GlobalLandTemperaturesByCity.csv\n",
      "│   ├── GlobalLandTemperaturesByCountry.csv\n",
      "│   ├── GlobalLandTemperaturesByMajorCity.csv\n",
      "│   ├── GlobalLandTemperaturesByState.csv\n",
      "│   ├── GlobalTemperatures.csv\n",
      "│   └── metadata.txt\n",
      "└── UNGreenhouseGasInventoryData/\n",
      "    ├── .DS_Store\n",
      "    ├── Co2.csv\n",
      "    ├── Hydrofluorocarbons.csv\n",
      "    ├── metadata.txt\n",
      "    ├── Methane.csv\n",
      "    ├── Nitrogen_trifluoride.csv\n",
      "    ├── Nitrous_oxide.csv\n",
      "    ├── Perfluorocarbons.csv\n",
      "    └── Sulphur_hexafluoride.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"/Users/jamesmoro/Documents/Python/ClimateData/data/raw\"\n",
    "paths = DisplayablePath.make_tree(Path(DATA_DIR))\n",
    "for path in paths:\n",
    "    print(path.displayable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0429763f-3717-49e7-98d7-e6ab5a008c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBALTEMP_DIR = Path(r\"/Users/jamesmoro/Documents/Python/ClimateData/data/raw\", \"GlobalTemperatures/\")\n",
    "GLOBALTEMPS_FILES = [\n",
    "    \"GlobalLandTemperaturesByCity\",\n",
    "    \"GlobalLandTemperaturesByCountry\",\n",
    "    \"GlobalLandTemperaturesByMajorCity\",\n",
    "    \"GlobalLandTemperaturesByState\",\n",
    "    \"GlobalTemperatures\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1897cd-b2c8-4420-9cfb-57ba13c652cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "globaltemps_paths = [str(Path(GLOBALTEMP_DIR,file+\".csv\")) for file in GLOBALTEMPS_FILES] #have to convert back to str to read in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3059f0be-5b91-4ede-9dc9-6cd36f198152",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREENHOUSEGAS_DIR = Path(r\"/Users/jamesmoro/Documents/Python/ClimateData/data/raw\", \"UNGreenhouseGasInventoryData/\")\n",
    "\n",
    "GREENHOUSEGAS_FILES = [\n",
    "    \"Co2\", \n",
    "    \"Hydrofluorocarbons\",\n",
    "    \"Methane\", \n",
    "    \"Nitrogen_trifluoride\", \n",
    "    \"Nitrous_oxide\",\n",
    "    \"Perfluorocarbons\",\n",
    "    \"Sulphur_hexafluoride\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690aede9-12ba-4634-9c57-7db2184392f8",
   "metadata": {},
   "source": [
    "### Greenhouse Gas Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60128f6c-60ac-4321-825c-c1dbac281059",
   "metadata": {},
   "outputs": [],
   "source": [
    "greenhousegas_paths = [str(Path(GREENHOUSEGAS_DIR,file+\".csv\")) for file in GREENHOUSEGAS_FILES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db7b3c8-5a1e-42a6-bf0b-8f5368099468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+----------------+\n",
      "|Country or Area|Year|           Value|\n",
      "+---------------+----+----------------+\n",
      "|      Australia|2018|415953.946668257|\n",
      "|      Australia|2017| 415097.42766819|\n",
      "+---------------+----+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_read_csv(greenhousegas_paths[0]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9358e32-eec8-4cc9-9c95-43af101d30e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Co2': 1247,\n",
       " 'Hydrofluorocarbons': 1149,\n",
       " 'Methane': 1247,\n",
       " 'Nitrogen_trifluoride': 316,\n",
       " 'Nitrous_oxide': 1247,\n",
       " 'Perfluorocarbons': 978,\n",
       " 'Sulphur_hexafluoride': 1207}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greenhousegas_count = {Path(file).stem:(spark_read_csv(file)).count() for file in greenhousegas_paths}\n",
    "greenhousegas_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "257e1cdb-f670-48a9-86df-54f209d09292",
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2 = spark_read_csv(greenhousegas_paths[0])\n",
    "HFC = spark_read_csv(greenhousegas_paths[1])\n",
    "CH4 = spark_read_csv(greenhousegas_paths[2])\n",
    "NF3 = spark_read_csv(greenhousegas_paths[3])\n",
    "N20 = spark_read_csv(greenhousegas_paths[4])\n",
    "PFC = spark_read_csv(greenhousegas_paths[5])\n",
    "SF6 = spark_read_csv(greenhousegas_paths[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ea90814-2252-4687-9ab0-2e13de5a82ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country or Area: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Value: double (nullable = true)\n",
      "\n",
      "+---------------+----+----------------+\n",
      "|Country or Area|Year|           Value|\n",
      "+---------------+----+----------------+\n",
      "|      Australia|2018|415953.946668257|\n",
      "|      Australia|2017| 415097.42766819|\n",
      "|      Australia|2016|411031.531117043|\n",
      "|      Australia|2015|401554.757230168|\n",
      "|      Australia|2014|394116.891505507|\n",
      "+---------------+----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CO2.printSchema()\n",
    "CO2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183c994-343b-48fe-9841-d9c6cfb82941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7cbf9-d3eb-4e38-837a-ae8dca1d2f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b0ef3e3-d78e-4e40-91e2-1eb09e1b83a1",
   "metadata": {},
   "source": [
    "### Globaltemp File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24148349-c405-4ba2-858b-72fc69748867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_read_csv(globaltemps_paths[0]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06313326-3ac5-4307-852c-882be55ce463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GlobalLandTemperaturesByCity': 8599212,\n",
       " 'GlobalLandTemperaturesByCountry': 577462,\n",
       " 'GlobalLandTemperaturesByMajorCity': 239177,\n",
       " 'GlobalLandTemperaturesByState': 645675,\n",
       " 'GlobalTemperatures': 3192}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globaltemps_count = {Path(file).stem:(spark_read_csv(file)).count() for file in globaltemps_paths}\n",
    "globaltemps_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce4aba4-8fa6-4b24-bc94-2b30e702a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cities = spark_read_csv(globaltemps_paths[0])\n",
    "country = spark_read_csv(globaltemps_paths[1])\n",
    "majorcity = spark_read_csv(globaltemps_paths[2])\n",
    "state = spark_read_csv(globaltemps_paths[3])\n",
    "globaltemps = spark_read_csv(globaltemps_paths[4])\n",
    "\n",
    "temp_df_list = [cities,country,majorcity,state,globaltemps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc67252-a0ca-4159-adca-4d35f7ffeab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8599212 rows\n",
      "----------------------\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "None\n",
      "There are 577462 rows\n",
      "----------------------\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "None\n",
      "There are 239177 rows\n",
      "----------------------\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "None\n",
      "There are 645675 rows\n",
      "----------------------\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMaxTemperature: double (nullable = true)\n",
      " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMinTemperature: double (nullable = true)\n",
      " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n",
      "None\n",
      "There are 3192 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataframe_summary(df) for df in temp_df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375badbf-b146-4bc0-a48a-2630abb5000e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3f0ca-51db-4efa-b95c-13474d1c65ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4fca5-1e7d-437f-9641-cee05c1972dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769d39f-83b6-4a49-b877-fd54578c3198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77779fc-d84a-4b9a-867b-d9a478738438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
